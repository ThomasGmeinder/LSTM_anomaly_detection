{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b246b6d",
   "metadata": {},
   "source": [
    "# LSTM trained for Anomaly Detection in Time-Series Data, quantized to INT8 TFLite format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b085ab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pathlib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75282a6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d194582",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=42 \n",
    "random.seed(SEED) \n",
    "\n",
    "UNROLL = False  # Use dynamic unrolling for LSTM\n",
    "\n",
    "if UNROLL:\n",
    "    model_file = \"lstm_model_unrolled_fp32.keras\"\n",
    "    tflite_file = \"lstm_model_unrolled_int8_quantized.tflite\"\n",
    "else:\n",
    "    model_file = \"lstm_model_fp32.keras\"\n",
    "    tflite_file = \"lstm_model_int8_quantized.tflite\"\n",
    "    \n",
    "FEATURES = 1\n",
    "SEQ_LEN = 100\n",
    "TRAINING_BATCH_SIZE = 8\n",
    "INFERENCE_BATCH_SIZE = 1\n",
    "NUM_SAMPLES = 1000  # Increased for better generalization\n",
    "HIDDEN_UNITS = 32   # Reduced to prevent overfitting\n",
    "\n",
    "# suppress warnings\n",
    "import logging\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # 0 = all logs, 1 = filter INFO, 2 = +WARNING, 3 = ERROR only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6dd7f3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Prepare training data\n",
    "### Generate synthetic time-series data for anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be7500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((NUM_SAMPLES, SEQ_LEN, FEATURES), dtype=np.float32)\n",
    "y = np.zeros((NUM_SAMPLES, 1), dtype=np.float32)\n",
    "\n",
    "for i in range(NUM_SAMPLES):\n",
    "\n",
    "    # Normal: smooth sinusoidal pattern with noise\n",
    "    t = np.linspace(0, 8 * np.pi, SEQ_LEN)\n",
    "    series = np.sin(t) + 0.1 * np.random.normal(0, 0.2, size=SEQ_LEN)\n",
    "    label = 0.0\n",
    "    \n",
    "    if i % 3 == 0:\n",
    "        # inject spikes anomaly for 30 percent of samples\n",
    "        # random nbumber of spikes between 1 and 5\n",
    "        num_spikes = np.random.randint(1, 6)\n",
    "        spike_indices = np.random.choice(SEQ_LEN, size=num_spikes, replace=False)\n",
    "        # random spike magnitude between 1 and 5\n",
    "        series[spike_indices] += np.random.uniform(1, 6, size=num_spikes)\n",
    "        label = 1.0\n",
    "\n",
    "    X[i, :, 0] = series\n",
    "    y[i, 0] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d5891c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Normalize input data to improve training stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6107639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (X - np.mean(X)) / np.std(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05943078",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Split data into train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2718998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70% train, 15% validation, 15% test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=SEED)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dbb1e7",
   "metadata": {},
   "source": [
    "### Save test data to files for C++ use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bce0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving test data to files for C++ inference run use...\")\n",
    "np.savetxt(\"X_test.txt\", X_test.reshape(X_test.shape[0], -1), delimiter=' ')\n",
    "np.savetxt(\"y_test.txt\", y_test, delimiter=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8fe752",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Load or create/train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacdb172",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n## Loading or creating the LSTM model...\")\n",
    "if os.path.exists(model_file):\n",
    "    print(f\"Loading existing model from {model_file}\")\n",
    "    model = tf.keras.models.load_model(model_file)\n",
    "else:\n",
    "    # Define the model with regularization\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(SEQ_LEN, FEATURES)),\n",
    "        tf.keras.layers.LSTM(HIDDEN_UNITS, unroll=UNROLL, dropout=0.2, recurrent_dropout=0.2),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    print(\"No existing model found. A new model will be created.\")\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=20,\n",
    "        batch_size=TRAINING_BATCH_SIZE,\n",
    "        callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)]\n",
    "    )\n",
    "    # save trained model\n",
    "    print(\"Training complete. Saving the model as \", model_file)\n",
    "    model.save(model_file)\n",
    "\n",
    "    # Plot training and validation loss\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(\"Training vs Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Binary Crossentropy\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaa8d70",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfc94ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n## Evaluating the model on test data\")\n",
    "loss, accuracy = model.evaluate(X_test, y_test, batch_size=INFERENCE_BATCH_SIZE)\n",
    "print(f\"FP32 Test Accuracy from evaluate: {accuracy:.8f}, Loss: {loss:.8f}\")\n",
    "\n",
    "fp32_preds = model.predict(X_test, batch_size=INFERENCE_BATCH_SIZE)\n",
    "\n",
    "# double check accuracy\n",
    "fp32_preds_rounded = (fp32_preds > 0.5).astype(np.float32)\n",
    "fp32_accuracy = np.mean(fp32_preds_rounded.flatten() == y_test.flatten())\n",
    "print(f\"FP32 Model Test Accuracy from predict: {fp32_accuracy:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156a98ab",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Visualise some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ec8e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, figsize=(12, 6))\n",
    "fig.suptitle(\"Sample Predictions from FP32 Model\")\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.plot(X_test[i].squeeze(), label='Sensor Signal')\n",
    "    ax.set_title(f\"True Label: {int(y_test[i][0])}, Predicted: {fp32_preds[i][0]:.2f}\")\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872a9c83",
   "metadata": {},
   "source": [
    "## Quantize and convert to the TFLite format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac071784",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n## Quantize and convert to the TFLite format\")\n",
    "# Quantization representative dataset\n",
    "def representative_dataset():\n",
    "    for i in range(100):\n",
    "        yield [X_train[i:i+1]]\n",
    "\n",
    "# Convert to quantized TFLite model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "if not UNROLL:\n",
    "    converter.target_spec.supported_ops.append(tf.lite.OpsSet.SELECT_TF_OPS)\n",
    "    converter._experimental_lower_tensor_list_ops = False\n",
    "\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "# Save quantized model\n",
    "tflite_model = converter.convert()\n",
    "pathlib.Path(tflite_file).write_bytes(tflite_model)\n",
    "print(f\"INT8-quantized model saved as {tflite_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e2f4a1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Evaluate TFLite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27be875",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "print(\"\\n## Evaluating the INT8 TFLite model\")\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_file)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "def run_tflite_model(interpreter, X):\n",
    "    input_scale, input_zero_point = input_details[0]['quantization']\n",
    "    output_scale, output_zero_point = output_details[0]['quantization']\n",
    "\n",
    "    preds = []\n",
    "    for i in range(len(X)):\n",
    "        x = X[i:i+1]\n",
    "        x_int8 = np.round(x / input_scale + input_zero_point).astype(np.int8)\n",
    "        interpreter.set_tensor(input_details[0]['index'], x_int8)\n",
    "        interpreter.invoke()\n",
    "        output = interpreter.get_tensor(output_details[0]['index'])\n",
    "        output = (output.astype(np.float32) - output_zero_point) * output_scale\n",
    "        preds.append(output[0])\n",
    "    return np.array(preds)\n",
    "\n",
    "int8_preds = run_tflite_model(interpreter, X_test)\n",
    "int8_preds = (int8_preds > 0.5).astype(np.float32)\n",
    "int8_accuracy = np.mean(int8_preds.flatten() == y_test.flatten())\n",
    "print(f\"INT8 Quantized Model Test Accuracy: {int8_accuracy:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5157eac",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Compare accuracy of FP32 and INT8 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d550083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n## Comparing accuracy of FP32 and INT8 models\")\n",
    "print(f\"FP32 Test Accuracy: {accuracy:.8f}\")\n",
    "print(f\"INT8 Quantized Model Test Accuracy: {int8_accuracy:.8f}\")\n",
    "# accuracy difference should be minimal, around 1-2% loss in accuracy\n",
    "print(f\"Difference in accuracy: {accuracy - int8_accuracy:.8f}\") \n",
    "# print hyperparameters\n",
    "print(f\"Hyperparameters: UNROLL={UNROLL}, FEATURES={FEATURES}, SEQ_LEN={SEQ_LEN}, \"\n",
    "      f\"TRAINING_BATCH_SIZE={TRAINING_BATCH_SIZE}, INFERENCE_BATCH_SIZE={INFERENCE_BATCH_SIZE}, \"\n",
    "      f\"NUM_SAMPLES={NUM_SAMPLES}, HIDDEN_UNITS={HIDDEN_UNITS}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
