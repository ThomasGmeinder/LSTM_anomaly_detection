{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efadce98",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# LSTM trained for Anomaly Detection in Time-Series Data\n",
    "This example creates an LSTM in Tensorflow for the purpose of detecting anomalies in time series data.\n",
    "The model is trained with sinusoidal data plus noise (normal case). Random spikes are added to generate anomalies.\n",
    "The trained model is then saved, quantized to int8 and converted to .tflite format.\n",
    "\n",
    "Finally, inference is run with the original fp32 model and the quantized .tflite model to determine the difference in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f831cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pathlib\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b8e279",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837c439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=42 \n",
    "random.seed(SEED) \n",
    "\n",
    "UNROLL = True  # Use dynamic unrolling for LSTM\n",
    "\n",
    "if UNROLL:\n",
    "    model_file = \"lstm_model_unrolled_fp32.keras\"\n",
    "    tflite_file = \"lstm_model_unrolled_int8_quantized.tflite\"\n",
    "else:\n",
    "    model_file = \"lstm_model_fp32.keras\"\n",
    "    tflite_file = \"lstm_model_int8_quantized.tflite\"\n",
    "    \n",
    "FEATURES = 1\n",
    "SEQ_LEN = 100\n",
    "TRAINING_BATCH_SIZE = 8\n",
    "INFERENCE_BATCH_SIZE = 1\n",
    "NUM_SAMPLES = 1000  # Increased for better generalization\n",
    "HIDDEN_UNITS = 32   # Reduced to prevent overfitting\n",
    "\n",
    "# suppress warnings\n",
    "import logging\n",
    "import time\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # 0 = all logs, 1 = filter INFO, 2 = +WARNING, 3 = ERROR only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3478d6d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Prepare training data\n",
    "### Generate synthetic time-series data for anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324faabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((NUM_SAMPLES, SEQ_LEN, FEATURES), dtype=np.float32)\n",
    "y = np.zeros((NUM_SAMPLES, 1), dtype=np.float32)\n",
    "\n",
    "for i in range(NUM_SAMPLES):\n",
    "\n",
    "    # Normal: smooth sinusoidal pattern with noise\n",
    "    t = np.linspace(0, 8 * np.pi, SEQ_LEN)\n",
    "    series = np.sin(t) + 0.1 * np.random.normal(0, 0.2, size=SEQ_LEN)\n",
    "    label = 0.0\n",
    "    \n",
    "    if i % 3 == 0:\n",
    "        # inject spikes anomaly for 30 percent of samples\n",
    "        # random nbumber of spikes between 1 and 5\n",
    "        num_spikes = np.random.randint(1, 6)\n",
    "        spike_indices = np.random.choice(SEQ_LEN, size=num_spikes, replace=False)\n",
    "        # random spike magnitude between 1 and 5\n",
    "        series[spike_indices] += np.random.uniform(1, 6, size=num_spikes)\n",
    "        label = 1.0\n",
    "\n",
    "    X[i, :, 0] = series\n",
    "    y[i, 0] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e17eee4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Normalize input data to improve training stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ba9f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (X - np.mean(X)) / np.std(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb1db52",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Split data into train/val/test\n",
    "70% train, 15% validation, 15% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3886a63",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=SEED)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358df5b7",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Load or create/train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af38b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n## Loading or creating the LSTM model...\")\n",
    "if os.path.exists(model_file):\n",
    "    print(f\"Loading existing model from {model_file}\")\n",
    "    model = tf.keras.models.load_model(model_file)\n",
    "else:\n",
    "    # Define the model with regularization\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(SEQ_LEN, FEATURES)),\n",
    "        tf.keras.layers.LSTM(HIDDEN_UNITS, unroll=UNROLL, dropout=0.2, recurrent_dropout=0.2),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    print(f\"No existing model {model_file} found. A new model will be created.\")\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=20,\n",
    "        batch_size=TRAINING_BATCH_SIZE,\n",
    "        callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)]\n",
    "    )\n",
    "    # save trained model\n",
    "    print(\"Training complete. Saving the model as \", model_file)\n",
    "    model.save(model_file)\n",
    "\n",
    "    # Plot training and validation loss\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.title(\"Training vs Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Binary Crossentropy\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eec40c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Evaluate on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f329fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n## Evaluating the model on test data\")\n",
    "loss, accuracy = model.evaluate(X_test, y_test, batch_size=INFERENCE_BATCH_SIZE)\n",
    "print(f\"FP32 Test Accuracy from evaluate: {accuracy:.8f}, Loss: {loss:.8f}\")\n",
    "\n",
    "fp32_preds = model.predict(X_test, batch_size=INFERENCE_BATCH_SIZE)\n",
    "\n",
    "# double check accuracy\n",
    "fp32_preds_rounded = (fp32_preds > 0.5).astype(np.float32)\n",
    "fp32_accuracy = np.mean(fp32_preds_rounded.flatten() == y_test.flatten())\n",
    "print(f\"FP32 Model Test Accuracy from predict: {fp32_accuracy:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5ded00",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Visualise some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943ab250",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, figsize=(12, 6))\n",
    "fig.suptitle(\"Sample Predictions from FP32 Model\")\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.plot(X_test[i].squeeze(), label='Sensor Signal')\n",
    "    ax.set_title(f\"Anomaly Label: {int(y_test[i][0])}, Predicted: {fp32_preds[i][0]:.2f}\")\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e871717",
   "metadata": {},
   "source": [
    "## Quantize and convert to the TFLite format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e661b043",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n## Quantize and convert to the TFLite format\")\n",
    "# Quantization representative dataset\n",
    "def representative_dataset():\n",
    "    for i in range(100):\n",
    "        yield [X_train[i:i+1]]\n",
    "\n",
    "# Convert to quantized TFLite model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "if not UNROLL:\n",
    "    converter.target_spec.supported_ops.append(tf.lite.OpsSet.SELECT_TF_OPS)\n",
    "    converter._experimental_lower_tensor_list_ops = False\n",
    "\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "\n",
    "# Save quantized model\n",
    "tflite_model = converter.convert()\n",
    "pathlib.Path(tflite_file).write_bytes(tflite_model)\n",
    "print(f\"INT8-quantized model saved as {tflite_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4b7457",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Evaluate TFLite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f41656c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n## Evaluating the INT8 TFLite model\")\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_file)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "def run_tflite_model(interpreter, X):\n",
    "\n",
    "    input_scale, input_zero_point = input_details[0]['quantization']\n",
    "    output_scale, output_zero_point = output_details[0]['quantization']\n",
    "\n",
    "    preds = []\n",
    "    times = []\n",
    "    for i in range(len(X)):\n",
    "        x = X[i:i+1]\n",
    "        x_int8 = np.round(x / input_scale + input_zero_point).astype(np.int8)\n",
    "\n",
    "        interpreter.set_tensor(input_details[0]['index'], x_int8)\n",
    "        start_time = time.time()\n",
    "        interpreter.invoke()\n",
    "        end_time = time.time()\n",
    "\n",
    "        times.append(end_time - start_time)\n",
    "\n",
    "        output = interpreter.get_tensor(output_details[0]['index'])\n",
    "        output = (output.astype(np.float32) - output_zero_point) * output_scale\n",
    "        preds.append(output[0])\n",
    "\n",
    "    mean_time = sum(times) / len(times)\n",
    "    print(f\"Mean tflite inference time: {mean_time:.6f} seconds\")\n",
    "    return np.array(preds)\n",
    "\n",
    "tflite_preds = run_tflite_model(interpreter, X_test)\n",
    "tflite_preds = (tflite_preds > 0.5).astype(np.float32)\n",
    "int8_accuracy = np.mean(tflite_preds.flatten() == y_test.flatten())\n",
    "print(f\"INT8 Quantized Model Test Accuracy: {int8_accuracy:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccef0e46",
   "metadata": {},
   "source": [
    "## Prepare test data for inference runs on embedded target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66d44a6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Compute X_test_int8 and y_test_int8 using the same quantization parameters\n",
    "input_scale, input_zero_point = input_details[0]['quantization']\n",
    "X_test_int8 = np.round(X_test / input_scale + input_zero_point).astype(np.int8)\n",
    "y_test_int8 = y_test.astype(np.int8)  # y is already float32, so we can convert it directly to int8\n",
    "\n",
    "# Output X_test_int8 and y_test_int8 to txt files for C++ use\n",
    "np.savetxt(\"X_test_int8.txt\", X_test_int8.reshape(-1, SEQ_LEN * FEATURES), fmt='%d')\n",
    "np.savetxt(\"y_test_int8.txt\", y_test_int8, fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6f10ed",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Compare accuracy of FP32 and INT8 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036cb785",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n## Comparing accuracy of FP32 and INT8 models\")\n",
    "print(f\"FP32 Test Accuracy: {accuracy:.8f}\")\n",
    "print(f\"INT8 Quantized Model Test Accuracy: {int8_accuracy:.8f}\")\n",
    "# accuracy difference should be minimal, around 1-2% loss in accuracy\n",
    "print(f\"Difference in accuracy: {accuracy - int8_accuracy:.8f}\") \n",
    "# print hyperparameters\n",
    "print(f\"Hyperparameters: UNROLL={UNROLL}, FEATURES={FEATURES}, SEQ_LEN={SEQ_LEN}, \"\n",
    "      f\"TRAINING_BATCH_SIZE={TRAINING_BATCH_SIZE}, INFERENCE_BATCH_SIZE={INFERENCE_BATCH_SIZE}, \"\n",
    "      f\"NUM_SAMPLES={NUM_SAMPLES}, HIDDEN_UNITS={HIDDEN_UNITS}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
